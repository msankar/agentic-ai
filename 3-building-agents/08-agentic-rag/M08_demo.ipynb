{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796124ec",
   "metadata": {},
   "source": [
    "# Module 08: Agentic RAG\n",
    "This notebook demonstrates how traditional Chroma DB works for RAG pipelines.\n",
    "\n",
    "## What we'll learn:\n",
    "- ChromaDB\n",
    "- OpenAI Embeddings\n",
    "- RAG using State Machine\n",
    "- Retrieval, Augment and Generation as steps"
   ]
  },
  {
   "cell_type": "code",
   "id": "7da7e9c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:27:10.642239Z",
     "start_time": "2025-11-05T21:27:10.639623Z"
    }
   },
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "dca83ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:15.494280Z",
     "start_time": "2025-11-05T21:28:15.303528Z"
    }
   },
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.api.models.Collection import Collection\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List\n",
    "\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from lib.llm import LLM\n",
    "from lib.messages import BaseMessage, UserMessage, SystemMessage"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c4c4424a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:18.650597Z",
     "start_time": "2025-11-05T21:28:18.648762Z"
    }
   },
   "source": [
    "import logging\n",
    "logging.getLogger('pdfminer').setLevel(logging.ERROR)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2744c74c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:19.765313Z",
     "start_time": "2025-11-05T21:28:19.761062Z"
    }
   },
   "source": [
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "606d2b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:23.255982Z",
     "start_time": "2025-11-05T21:28:23.254197Z"
    }
   },
   "source": [
    "sentence_list = [\n",
    "    \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "    \"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "    \"Google is bringing Gemini to all older Pixel Buds\",\n",
    "    \"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "    \"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "]\n",
    "ids = [\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "c7858167",
   "metadata": {},
   "source": [
    "## ChromaDB with Default Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bff2de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:29.064611Z",
     "start_time": "2025-11-05T21:28:28.995363Z"
    }
   },
   "source": [
    "chroma_client = chromadb.Client()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "75924db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:33.711830Z",
     "start_time": "2025-11-05T21:28:33.707467Z"
    }
   },
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "9b4d5903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:40.425920Z",
     "start_time": "2025-11-05T21:28:37.026376Z"
    }
   },
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malathi.sankar/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 33.8MiB/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "93e79ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:49.943436Z",
     "start_time": "2025-11-05T21:28:49.939163Z"
    }
   },
   "source": [
    "collection.count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "26202218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:28:52.297759Z",
     "start_time": "2025-11-05T21:28:52.291476Z"
    }
   },
   "source": [
    "collection.peek(1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1'],\n",
       " 'embeddings': array([[ 6.06655143e-02, -3.51322480e-02,  6.06437288e-02,\n",
       "         -5.11925854e-02,  1.13580197e-01, -1.88892763e-02,\n",
       "         -2.68528331e-02,  5.48633784e-02,  3.23644504e-02,\n",
       "          5.42442985e-02, -4.04198468e-02, -1.90558676e-02,\n",
       "         -5.97919673e-02,  2.56032404e-02,  8.48459899e-02,\n",
       "          4.12196927e-02,  3.95206176e-02, -4.00091521e-02,\n",
       "         -7.66606703e-02,  2.78292280e-02,  5.38355187e-02,\n",
       "         -1.35247353e-02,  9.65649709e-02, -3.04361507e-02,\n",
       "          6.61455886e-03,  7.21730739e-02, -9.53866169e-02,\n",
       "         -2.75959335e-02,  7.86793791e-03, -6.68519735e-02,\n",
       "         -1.27341859e-02,  1.21338010e-01, -6.66138083e-02,\n",
       "         -3.28670517e-02, -6.49284273e-02, -1.61901880e-02,\n",
       "         -3.32960160e-03,  8.04080665e-02, -3.84503491e-02,\n",
       "          1.37278825e-04,  3.72596853e-03,  4.83831167e-02,\n",
       "         -3.65696087e-06, -4.51370180e-02, -1.37449345e-02,\n",
       "         -7.15254620e-02,  1.01806317e-02, -4.23029736e-02,\n",
       "          3.16683613e-02,  1.55983986e-02, -3.97931077e-02,\n",
       "         -5.78960441e-02, -6.40795799e-03,  5.05231433e-02,\n",
       "          1.33638028e-02, -6.78852126e-02,  1.05864527e-02,\n",
       "         -4.71998043e-02,  2.75698840e-03,  6.26822039e-02,\n",
       "          3.98217663e-02,  2.90143117e-03, -1.10629899e-02,\n",
       "         -3.56735885e-02,  1.66206136e-01,  2.18522109e-05,\n",
       "         -9.47266445e-03, -1.11342639e-01,  2.20047049e-02,\n",
       "         -5.18189110e-02, -1.24161493e-03, -1.01766353e-02,\n",
       "          2.69737039e-02,  4.42355014e-02, -6.56566024e-02,\n",
       "          3.83598581e-02,  4.76824455e-02, -3.88536416e-02,\n",
       "          6.39469102e-02,  2.61559170e-02,  1.20892607e-01,\n",
       "         -9.07306932e-03, -3.85694169e-02,  2.28223912e-02,\n",
       "          5.07763820e-03, -1.89749748e-02, -2.87914295e-02,\n",
       "         -5.56396134e-02, -8.60800594e-03,  5.86411171e-03,\n",
       "          5.63661344e-02,  6.81668753e-03,  4.91599105e-02,\n",
       "          1.10514201e-01, -3.60370390e-02, -2.38150060e-02,\n",
       "         -1.63016450e-02, -3.64761427e-02, -3.18400078e-02,\n",
       "          8.61765891e-02,  3.62226032e-02, -8.32575187e-02,\n",
       "         -3.95189337e-02, -3.90899740e-03,  6.57732785e-03,\n",
       "         -5.79330213e-02,  7.79308453e-02, -2.28360966e-02,\n",
       "         -5.00358939e-02,  6.03723992e-03, -8.09533987e-03,\n",
       "          4.45688926e-02,  4.15953668e-03,  4.67504375e-02,\n",
       "         -4.04252224e-02,  7.59720951e-02,  3.34815867e-02,\n",
       "          2.89951228e-02,  2.71279365e-02,  1.18415598e-02,\n",
       "         -5.04887253e-02, -4.75644283e-02,  4.13297340e-02,\n",
       "         -1.27794761e-02,  9.69001576e-02, -3.82148959e-02,\n",
       "         -8.40062946e-02, -2.62858592e-33,  2.09661480e-02,\n",
       "         -2.21719244e-03, -3.44077796e-02,  3.05706766e-02,\n",
       "          1.03635691e-01, -4.35035676e-02, -2.39832383e-02,\n",
       "          1.93832591e-02, -4.34555225e-02, -4.16072719e-02,\n",
       "         -4.09181975e-02,  1.49111822e-02, -5.59189208e-02,\n",
       "          8.51473957e-02, -5.81931183e-03, -6.91417828e-02,\n",
       "          2.26447023e-02, -4.11436185e-02,  4.50275727e-02,\n",
       "         -5.11199050e-02,  7.75629655e-02,  1.48884561e-02,\n",
       "         -1.96786528e-03,  3.21936272e-02, -6.81291297e-02,\n",
       "          1.49353713e-01,  5.72788045e-02, -1.83641948e-02,\n",
       "          2.92006712e-02,  7.61159956e-02, -1.02901466e-01,\n",
       "         -7.13463873e-03,  3.35425660e-02,  3.48334685e-02,\n",
       "         -1.32390461e-03,  2.54912418e-03, -4.71515208e-02,\n",
       "          2.60245651e-02, -3.65419239e-02, -3.68678756e-02,\n",
       "         -2.72565125e-03,  2.17560846e-02, -1.12910651e-01,\n",
       "         -2.99250167e-02, -2.38775108e-02, -6.51453808e-02,\n",
       "          1.16426812e-03,  1.92630515e-02, -1.62156206e-02,\n",
       "          2.74781324e-02,  5.08512631e-02,  2.73107737e-02,\n",
       "         -2.71648765e-02,  3.59324142e-02, -5.81061952e-02,\n",
       "         -2.63196100e-02,  8.34811945e-03, -2.87828315e-02,\n",
       "          5.10963723e-02,  2.35959683e-02,  1.05895447e-02,\n",
       "         -3.48851793e-02, -2.97376011e-02,  6.21797703e-02,\n",
       "          4.96875532e-02,  2.55152886e-03, -6.37624366e-03,\n",
       "         -1.16777914e-02, -2.02132538e-02, -1.37591064e-02,\n",
       "         -4.81716171e-03,  5.53599633e-02,  9.78665706e-03,\n",
       "         -7.64255449e-02, -7.46814832e-02, -7.68535659e-02,\n",
       "         -1.85833499e-02,  2.21995614e-03,  6.74626827e-02,\n",
       "          2.59036664e-03,  1.15022510e-02,  8.59656483e-02,\n",
       "          1.94990309e-03, -2.49749441e-02, -1.21855680e-02,\n",
       "         -9.39004961e-03,  5.22418804e-02, -6.60095364e-02,\n",
       "         -5.23915403e-02, -1.49593139e-02,  5.78218438e-02,\n",
       "         -4.54941345e-03,  1.08560054e-02, -2.10044924e-02,\n",
       "          3.67957130e-02,  1.63442883e-33, -7.54486769e-02,\n",
       "         -3.71569325e-03, -3.30684222e-02,  2.56322399e-02,\n",
       "         -2.14399826e-02,  4.71698400e-03, -1.03810243e-02,\n",
       "          8.87744576e-02, -2.98751388e-02,  2.86101401e-02,\n",
       "         -2.06580330e-02,  2.60161385e-02, -4.75596972e-02,\n",
       "         -4.82040085e-03,  6.41304106e-02, -5.69466576e-02,\n",
       "          6.49288520e-02, -1.38111889e-01,  5.93989380e-02,\n",
       "         -2.20186892e-03,  9.33878124e-02,  1.50098493e-02,\n",
       "          4.26072255e-03,  3.95668931e-02, -9.17595997e-02,\n",
       "          2.03433447e-02, -2.72352882e-02, -5.06100692e-02,\n",
       "         -1.51934521e-02,  2.40814872e-02,  3.84032652e-02,\n",
       "          3.39480094e-03, -7.48484656e-02, -8.21176246e-02,\n",
       "          4.00837399e-02,  2.33298298e-02, -6.00908250e-02,\n",
       "          5.34814708e-02, -1.25419637e-02,  2.78938226e-02,\n",
       "          3.23283561e-02,  3.38679589e-02, -4.77768481e-02,\n",
       "         -2.36944538e-02, -2.43718531e-02, -1.29209859e-02,\n",
       "         -3.73663828e-02, -7.32498197e-03,  1.32506743e-01,\n",
       "          1.91214997e-02,  6.31476343e-02, -1.37641549e-01,\n",
       "          2.43645422e-02, -8.76890570e-02,  1.23712691e-02,\n",
       "         -6.28761947e-02,  3.14168148e-02, -3.93745340e-02,\n",
       "         -4.52678651e-02,  7.16478452e-02,  2.08713207e-02,\n",
       "         -5.34157790e-02, -1.12925671e-01, -1.13975413e-01,\n",
       "          4.04910147e-02,  1.17943235e-01,  1.55132115e-02,\n",
       "         -2.58247647e-02,  1.85811445e-02, -1.60459206e-02,\n",
       "          4.09773588e-02, -2.11305707e-03, -8.62064064e-02,\n",
       "         -1.21933796e-01, -4.25353879e-03,  7.11879283e-02,\n",
       "         -5.73185980e-02,  2.77414434e-02,  4.37273905e-02,\n",
       "         -1.63027011e-02,  7.85875320e-03, -1.62095952e-04,\n",
       "          1.68788303e-02, -4.39421535e-02, -1.87049282e-03,\n",
       "         -2.03024391e-02, -6.98392419e-03,  1.07339174e-01,\n",
       "         -2.07638163e-02,  5.85731715e-02,  3.52921523e-02,\n",
       "          5.86631708e-02,  9.77355056e-03,  5.34894504e-02,\n",
       "          1.68920346e-02, -2.19190568e-08, -2.95748375e-02,\n",
       "         -3.72208878e-02, -3.73911671e-02,  9.28657055e-02,\n",
       "          5.08170798e-02,  4.79653180e-02, -2.35483553e-02,\n",
       "          4.04021405e-02,  1.42101496e-01,  2.74159368e-02,\n",
       "          4.89008129e-02, -3.25187035e-02, -3.06229815e-02,\n",
       "          7.28012547e-02,  9.97485965e-02,  8.45942833e-03,\n",
       "         -1.95342470e-02,  1.80619583e-02, -6.47281334e-02,\n",
       "         -7.73269832e-02, -5.81529252e-02,  5.26529271e-03,\n",
       "          9.64109674e-02, -1.43653944e-01,  1.17099006e-02,\n",
       "          1.02300551e-02, -1.01575755e-01,  2.90962216e-02,\n",
       "          2.15431321e-02,  6.96388036e-02, -4.70430404e-02,\n",
       "         -1.47150028e-02, -3.34388837e-02, -1.19947586e-02,\n",
       "         -5.77425212e-02,  3.00532579e-03, -1.48846032e-02,\n",
       "         -3.33915874e-02, -1.70223694e-02, -2.78871935e-02,\n",
       "          8.31423476e-02, -4.47395742e-02, -1.68330856e-02,\n",
       "          4.41733822e-02, -4.54890989e-02, -1.81377400e-02,\n",
       "         -8.59706849e-02,  4.01952490e-03, -3.17578353e-02,\n",
       "         -3.56248859e-03, -7.62890466e-03, -6.97051436e-02,\n",
       "         -1.55669665e-02,  1.00138381e-01,  5.05658053e-02,\n",
       "          3.08240987e-02, -1.35543430e-02,  2.54797284e-02,\n",
       "          5.19401021e-02,  1.28921226e-03,  6.60767257e-02,\n",
       "         -2.51749828e-02, -9.04038474e-02,  5.78943454e-02]]),\n",
       " 'documents': [\"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [None]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "f2a4c9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:02.512308Z",
     "start_time": "2025-11-05T21:29:02.445656Z"
    }
   },
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[1.5251753330230713, 1.7548508644104004]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "d9bdc20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:06.702719Z",
     "start_time": "2025-11-05T21:29:06.636995Z"
    }
   },
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")\n",
    "\n",
    "result['documents'][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google is bringing Gemini to all older Pixel Buds',\n",
       " \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1044d051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:12.816573Z",
     "start_time": "2025-11-05T21:29:12.814621Z"
    }
   },
   "source": [
    "print(collection._embedding_function.name())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "6e96ba3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:14.983577Z",
     "start_time": "2025-11-05T21:29:14.980598Z"
    }
   },
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 384\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "239cbe2d",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "id": "00b29b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:18.341934Z",
     "start_time": "2025-11-05T21:29:18.338926Z"
    }
   },
   "source": [
    "chroma_client.delete_collection(name=\"demo\")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "4d0982f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:19.345175Z",
     "start_time": "2025-11-05T21:29:19.338992Z"
    }
   },
   "source": [
    "embeddings_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "6130e20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:20.494957Z",
     "start_time": "2025-11-05T21:29:20.491819Z"
    }
   },
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "16673d1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T21:29:23.120470Z",
     "start_time": "2025-11-05T21:29:22.682383Z"
    }
   },
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: voc-1454**************************************6929. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} in add.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAuthenticationError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mcollection\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43msentence_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/api/models/Collection.py:86\u001B[39m, in \u001B[36mCollection.add\u001B[39m\u001B[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34madd\u001B[39m(\n\u001B[32m     52\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     53\u001B[39m     ids: OneOrMany[ID],\n\u001B[32m   (...)\u001B[39m\u001B[32m     63\u001B[39m     uris: Optional[OneOrMany[URI]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     64\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     65\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Add embeddings to the data store.\u001B[39;00m\n\u001B[32m     66\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m     67\u001B[39m \u001B[33;03m        ids: The ids of the embeddings you wish to add\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     83\u001B[39m \n\u001B[32m     84\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m     add_request = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_and_prepare_add_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     91\u001B[39m \u001B[43m        \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[43m        \u001B[49m\u001B[43muris\u001B[49m\u001B[43m=\u001B[49m\u001B[43muris\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     93\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28mself\u001B[39m._client._add(\n\u001B[32m     96\u001B[39m         collection_id=\u001B[38;5;28mself\u001B[39m.id,\n\u001B[32m     97\u001B[39m         ids=add_request[\u001B[33m\"\u001B[39m\u001B[33mids\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    103\u001B[39m         database=\u001B[38;5;28mself\u001B[39m.database,\n\u001B[32m    104\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:103\u001B[39m, in \u001B[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001B[32m    102\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    104\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    105\u001B[39m         msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:241\u001B[39m, in \u001B[36mCollectionCommon._validate_and_prepare_add_request\u001B[39m\u001B[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m    239\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m add_records[\u001B[33m\"\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    240\u001B[39m     validate_record_set_for_embedding(record_set=add_records)\n\u001B[32m--> \u001B[39m\u001B[32m241\u001B[39m     add_embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed_record_set\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_records\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    243\u001B[39m     add_embeddings = add_records[\u001B[33m\"\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:724\u001B[39m, in \u001B[36mCollectionCommon._embed_record_set\u001B[39m\u001B[34m(self, record_set, embeddable_fields, is_query)\u001B[39m\n\u001B[32m    719\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._embed(\n\u001B[32m    720\u001B[39m                 \u001B[38;5;28minput\u001B[39m=\u001B[38;5;28mself\u001B[39m._data_loader(uris=cast(URIs, record_set[field])),  \u001B[38;5;66;03m# type: ignore[literal-required]\u001B[39;00m\n\u001B[32m    721\u001B[39m                 is_query=is_query,\n\u001B[32m    722\u001B[39m             )\n\u001B[32m    723\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m724\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43mrecord_set\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfield\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[literal-required]\u001B[39;49;00m\n\u001B[32m    726\u001B[39m \u001B[43m                \u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    727\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    728\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    729\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mRecord does not contain any non-None fields that can be embedded.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    730\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEmbeddable Fields: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00membeddable_fields\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    731\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mRecord Fields: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrecord_set\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    732\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:741\u001B[39m, in \u001B[36mCollectionCommon._embed\u001B[39m\u001B[34m(self, input, is_query)\u001B[39m\n\u001B[32m    739\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._embedding_function.embed_query(\u001B[38;5;28minput\u001B[39m=\u001B[38;5;28minput\u001B[39m)\n\u001B[32m    740\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m741\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embedding_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    743\u001B[39m config_ef = \u001B[38;5;28mself\u001B[39m.configuration.get(\u001B[33m\"\u001B[39m\u001B[33membedding_function\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m config_ef \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/api/types.py:775\u001B[39m, in \u001B[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    774\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m: EmbeddingFunction[D], \u001B[38;5;28minput\u001B[39m: D) -> Embeddings:\n\u001B[32m--> \u001B[39m\u001B[32m775\u001B[39m     result = \u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    776\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    777\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/openai_embedding_function.py:127\u001B[39m, in \u001B[36mOpenAIEmbeddingFunction.__call__\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m     embedding_params[\u001B[33m\"\u001B[39m\u001B[33mdimensions\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mself\u001B[39m.dimensions\n\u001B[32m    126\u001B[39m \u001B[38;5;66;03m# Get embeddings\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43membedding_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    129\u001B[39m \u001B[38;5;66;03m# Extract embeddings from response\u001B[39;00m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m [np.array(data.embedding, dtype=np.float32) \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m response.data]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/openai/resources/embeddings.py:128\u001B[39m, in \u001B[36mEmbeddings.create\u001B[39m\u001B[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    122\u001B[39m             embedding.embedding = np.frombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[32m    123\u001B[39m                 base64.b64decode(data), dtype=\u001B[33m\"\u001B[39m\u001B[33mfloat32\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    124\u001B[39m             ).tolist()\n\u001B[32m    126\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    129\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/embeddings\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    131\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    132\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    134\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    135\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/openai/_base_client.py:1239\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1225\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1226\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1227\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1234\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1235\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1236\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1237\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1238\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1239\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/agentic-ai/.venv/lib/python3.13/site-packages/openai/_base_client.py:1034\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1031\u001B[39m             err.response.read()\n\u001B[32m   1033\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1034\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1036\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1038\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mAuthenticationError\u001B[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: voc-1454**************************************6929. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} in add."
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c86941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   'The first Intel Battlmage GPU benchmarks have leaked']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[0.46601054072380066, 0.48678600788116455]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70061e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a68ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 1536\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66872a7",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c04c9",
   "metadata": {},
   "source": [
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16137bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"GlobalEVOutlook2025.pdf\"\n",
    "documents = []\n",
    "page_nums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5f6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(file_path) as pdf:\n",
    "    for num, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            documents.append(text)\n",
    "            page_nums.append(str(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d1d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"traditional_rag\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2273128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=page_nums\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb87904",
   "metadata": {},
   "source": [
    "**State Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bcdcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be570fcc",
   "metadata": {},
   "source": [
    "**RAG: Retrieve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d0d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:State, resource:Resource):\n",
    "    question = state[\"question\"]\n",
    "    collection:Collection = resource.vars.get(\"collection\")\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=3,\n",
    "        include=['documents']\n",
    "    )\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    \n",
    "    return {\"documents\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60429f",
   "metadata": {},
   "source": [
    "**RAG: Augment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a17a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(state:State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    context = \"\\n\\n\".join(documents)\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an assistant for question-answering tasks.\"),\n",
    "        UserMessage(\n",
    "            content=(\n",
    "                \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"If you don't know the answer, just say that you don't know. \"\n",
    "                f\"\\n# Question: \\n-> {question} \"\n",
    "                f\"\\n# Context: \\n-> {context} \"\n",
    "                \"\\n# Answer: \"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e9be5",
   "metadata": {},
   "source": [
    "**RAG: Generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ee61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:State, resource:Resource):\n",
    "    llm:LLM = resource.vars.get(\"llm\")\n",
    "    ai_message = llm.invoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"answer\": ai_message.content, \n",
    "        \"messages\": state[\"messages\"] + [ai_message],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3c7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateMachine(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f8d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "entry = EntryPoint()\n",
    "retrieve_step = Step(\"retrieve\", retrieve)\n",
    "augment_step = Step(\"augment\", augment)\n",
    "generate_step = Step(\"generate\", generate)\n",
    "termination = Termination()\n",
    "        \n",
    "workflow.add_steps(\n",
    "    [\n",
    "        entry, \n",
    "        retrieve_step, \n",
    "        augment_step, \n",
    "        generate_step, \n",
    "        termination\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf846ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, retrieve_step)\n",
    "workflow.connect(retrieve_step, augment_step)\n",
    "workflow.connect(augment_step, generate_step)\n",
    "workflow.connect(generate_step, termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "039f9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a656f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = Resource(\n",
    "    vars = {\n",
    "        \"llm\": llm,\n",
    "        \"collection\": collection,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c53eb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: State = {\n",
    "    \"question\": \"What was the number of electric car sales and their market share in Brazil in 2024?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1e9954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "run_object = workflow.run(initial_state, resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9231fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2024, Brazil had nearly 125,000 electric car sales, which represented a market share of 6.5%.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_object.get_final_state()[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c70358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

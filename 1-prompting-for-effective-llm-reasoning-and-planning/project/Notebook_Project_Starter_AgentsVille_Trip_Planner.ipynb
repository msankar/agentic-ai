{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Project: AgentsVille Trip Planner\n",
        "#\n",
        "# Welcome to your final project! In this notebook, you'll build the \"AgentsVille Trip Planner,\"\n",
        "# an AI-powered assistant that helps users plan trips to the imaginary city of AgentsVille.\n",
        "# You will apply the prompting techniques and agentic reasoning concepts you've learned\n",
        "# throughout the course.\n",
        "\n",
        "# Project Goal:\n",
        "# 1. Generate an initial, detailed travel itinerary based on user preferences.\n",
        "# 2. Enhance this itinerary using an AI agent that can use (simulated) tools.\n",
        "\n",
        "# --- 0. Setup ---\n",
        "# Import necessary libraries and set up the OpenAI client and helper functions.\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from enum import Enum\n",
        "from typing import List, Dict, Any, Optional, Literal\n",
        "\n",
        "from openai import OpenAI\n",
        "# Ensure you have pydantic installed: pip install pydantic\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Attempt to import from project_lib, provide stubs if not found\n",
        "try:\n",
        "    from project_lib import (\n",
        "        TravelPreferences, TravelItinerary, Activity, DayPlan, PackingListItem, # Pydantic Models\n",
        "        available_tools, # Dictionary of tool schemas and functions\n",
        "        # Tool implementations are called via available_tools dictionary\n",
        "        LLMToolCall # Pydantic model for tool calls\n",
        "    )\n",
        "    print(\"Successfully imported from project_lib.py\")\n",
        "except ImportError:\n",
        "    print(\"Warning: project_lib.py not found or some components are missing. Using placeholder Pydantic models and functions.\\n\",\n",
        "          \"Please ensure project_lib.py is in the same directory as this notebook for full functionality.\")\n",
        "\n",
        "    # Define dummy Pydantic models if project_lib is not available\n",
        "    class TravelPreferences(BaseModel):\n",
        "        destination: str\n",
        "        duration_days: int\n",
        "        travel_style: List[str]\n",
        "        interests: List[str]\n",
        "        budget: Literal[\"budget\", \"mid-range\", \"luxury\"]\n",
        "        specific_requests: Optional[str] = None\n",
        "\n",
        "    class Activity(BaseModel):\n",
        "        time: str\n",
        "        description: str\n",
        "        estimated_cost: Optional[str] = None\n",
        "        details: Optional[str] = None\n",
        "\n",
        "    class DayPlan(BaseModel):\n",
        "        day_number: int\n",
        "        theme: Optional[str] = None\n",
        "        activities: List[Activity]\n",
        "\n",
        "    class PackingListItem(BaseModel):\n",
        "        item: str\n",
        "        quantity: Optional[int] = 1\n",
        "        notes: Optional[str] = None\n",
        "\n",
        "    class TravelItinerary(BaseModel):\n",
        "        trip_name: str\n",
        "        destination: str\n",
        "        duration_days: int\n",
        "        daily_plans: List[DayPlan]\n",
        "        suggested_packing_list: Optional[List[PackingListItem]] = None\n",
        "        overall_estimated_budget: Optional[str] = None\n",
        "        notes: Optional[str] = None\n",
        "\n",
        "    class LLMToolCall(BaseModel): # For validating the LLM's desired tool call\n",
        "        name: str\n",
        "        arguments: Dict[str, Any]\n",
        "\n",
        "    # Dummy tool implementations (these would be in project_lib.py)\n",
        "    def get_weather_forecast(location: str, date: str) -> Dict[str, Any]:\n",
        "        print(f\"[Tool Stub] Called get_weather_forecast for {location} on {date}\")\n",
        "        return {\"forecast\": \"Sunny\", \"temperature\": \"22C\", \"location\": location, \"date\": date}\n",
        "\n",
        "    def search_activities(location: str, interests: List[str], date: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "        print(f\"[Tool Stub] Called search_activities for {location} with interests {interests} on {date}\")\n",
        "        return [{\"name\": \"Museum of Agentic Design\", \"description\": \"Explore the history of AI agents.\"}]\n",
        "\n",
        "    def find_restaurants(location: str, cuisine_type: Optional[str] = None, price_range: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "        print(f\"[Tool Stub] Called find_restaurants for {location}, cuisine {cuisine_type}, price {price_range}\")\n",
        "        return [{\"name\": \"The Prompt Cafe\", \"cuisine\": cuisine_type if cuisine_type else \"various\"}]\n",
        "\n",
        "    def book_hotel(location: str, check_in_date: str, check_out_date: str, preferences: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        print(f\"[Tool Stub] Called book_hotel for {location} from {check_in_date} to {check_out_date}\")\n",
        "        return {\"booking_confirmation\": \"HOTEL-STUB-CONFIRMED\", \"hotel_name\": \"The Grand Agent Hotel\"}\n",
        "\n",
        "    available_tools = {\n",
        "        \"get_weather_forecast\": {\n",
        "            \"function\": get_weather_forecast,\n",
        "            \"description\": \"Get the weather forecast for a specific location and date.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g., San Francisco, CA\"},\n",
        "                    \"date\": {\"type\": \"string\", \"description\": \"The date for the forecast, in YYYY-MM-DD format.\"}\n",
        "                },\n",
        "                \"required\": [\"location\", \"date\"]\n",
        "            }\n",
        "        },\n",
        "        \"search_activities\": {\n",
        "            \"function\": search_activities,\n",
        "            \"description\": \"Searches for activities based on location, interests, and optionally a date.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"The location to search for activities.\"},\n",
        "                    \"interests\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"A list of interests to guide the activity search.\"},\n",
        "                    \"date\": {\"type\": \"string\", \"description\": \"Optional. The specific date for activities, in YYYY-MM-DD format.\"}\n",
        "                },\n",
        "                \"required\": [\"location\", \"interests\"]\n",
        "            }\n",
        "        },\n",
        "        \"find_restaurants\": {\n",
        "            \"function\": find_restaurants,\n",
        "            \"description\": \"Finds restaurants based on location, cuisine type, and price range.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"The location to search for restaurants.\"},\n",
        "                    \"cuisine_type\": {\"type\": \"string\", \"description\": \"Optional. The desired type of cuisine (e.g., Italian, Mexican).\"},\n",
        "                    \"price_range\": {\"type\": \"string\", \"description\": \"Optional. The desired price range (e.g., $, $$, $$$).\"}\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        },\n",
        "        \"book_hotel\": {\n",
        "            \"function\": book_hotel,\n",
        "            \"description\": \"Books a hotel based on location, dates, and preferences.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"The location for the hotel.\"},\n",
        "                    \"check_in_date\": {\"type\": \"string\", \"description\": \"The check-in date in YYYY-MM-DD format.\"},\n",
        "                    \"check_out_date\": {\"type\": \"string\", \"description\": \"The check-out date in YYYY-MM-DD format.\"},\n",
        "                    \"preferences\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"description\": \"Optional. Dictionary of preferences like room type, amenities.\",\n",
        "                        \"properties\": {\n",
        "                             \"room_type\": {\"type\": \"string\", \"description\": \"e.g., King, Queen, Suite\"},\n",
        "                             \"amenities\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"e.g., ['pool', 'gym']\"}\n",
        "                        }\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\", \"check_in_date\", \"check_out_date\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "# OpenAI Client Setup\n",
        "# TODO: Configure your OpenAI API Key\n",
        "# Replace \"**********\" with your actual Vocareum OpenAI API Key.\n",
        "# Alternatively, if your classroom workspace sets the OPENAI_API_KEY environment variable,\n",
        "# you can use `api_key=os.getenv(\"OPENAI_API_KEY\")`.\n",
        "\n",
        "try:\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://openai.vocareum.com/v1\",\n",
        "        api_key=\"**********\"  # TODO: Replace \"**********\" with your key\n",
        "    )\n",
        "    print(\"OpenAI client configured (key needs to be set).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error configuring OpenAI client: {e}\")\n",
        "\n",
        "# Define helper functions\n",
        "class OpenAIModels(str, Enum):\n",
        "    GPT_41_MINI = \"gpt-4.1-mini\"\n",
        "\n",
        "MODEL = OpenAIModels.GPT_41_MINI\n",
        "\n",
        "def get_completion(messages: List[Dict[str, Any]], model: str = MODEL, temperature: float = 0.2, response_format: Optional[Dict[str, str]] = None) -> Optional[Any]:\n",
        "    \"\"\"\n",
        "    Function to get a completion from the OpenAI API.\n",
        "    Returns the message object if tool_calls are present, otherwise the content string.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        completion_params = {\n",
        "            \"model\": model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": temperature,\n",
        "        }\n",
        "        if response_format: # For requesting JSON mode\n",
        "            completion_params[\"response_format\"] = response_format\n",
        "\n",
        "        # For ReAct agent, we might need to pass tool schemas if using OpenAI's native tool calling.\n",
        "        # For this project, we are guiding the LLM to output JSON for tool calls in the ACT step.\n",
        "        # If using native tool calling, you would add 'tools' and 'tool_choice' parameters here.\n",
        "\n",
        "        response = client.chat.completions.create(**completion_params)\n",
        "        message = response.choices[0].message\n",
        "\n",
        "        if message.tool_calls: # Check for native tool calls (OpenAI v1.x+)\n",
        "            return message # Return the whole message object\n",
        "        return message.content # Return just the text content\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling OpenAI API: {e}\")\n",
        "        return None\n",
        "\n",
        "def print_messages(messages: List[Dict[str, Any]]):\n",
        "    \"\"\"Helper function to print messages, including tool calls and tool results.\"\"\"\n",
        "    for message in messages:\n",
        "        role = message.get('role', 'unknown').capitalize()\n",
        "        content = message.get('content')\n",
        "\n",
        "        display(Markdown(f\"**{role}:**\"))\n",
        "        if content and isinstance(content, str):\n",
        "            display(Markdown(content))\n",
        "\n",
        "        # Handling new tool_calls format (list of objects)\n",
        "        if message.get('role') == 'assistant' and message.get('tool_calls'):\n",
        "            display(Markdown(\"  *Wants to call tools:*\"))\n",
        "            for tc in message['tool_calls']:\n",
        "                function_info = tc.get('function', {})\n",
        "                display(Markdown(f\"  - **Tool Call ID:** {tc.get('id')}\"))\n",
        "                display(Markdown(f\"    - **Function:** `{function_info.get('name')}`\"))\n",
        "                display(Markdown(f\"    - **Arguments:** `{function_info.get('arguments')}`\"))\n",
        "\n",
        "        if message.get('role') == 'tool':\n",
        "            display(Markdown(f\"  *Tool Call Result (ID: {message.get('tool_call_id')}) for `{message.get('name')}`:*\"))\n",
        "            if content:\n",
        "                 display(Markdown(f\"    `{str(content)}`\"))\n",
        "        print(\"---\")\n",
        "\n",
        "# --- 1. Defining User Preferences (Input) ---\n",
        "user_preferences_data = {\n",
        "    \"destination\": \"AgentsVille\",\n",
        "    \"duration_days\": 3,\n",
        "    \"travel_style\": [\"culture\", \"history\", \"local experiences\"],\n",
        "    \"interests\": [\"museums\", \"historical landmarks\", \"local markets\", \"street food\"],\n",
        "    \"budget\": \"mid-range\",\n",
        "    \"specific_requests\": \"I'd like to visit at least one major museum and try authentic local cuisine. I prefer using public transport or walking.\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    user_prefs = TravelPreferences(**user_preferences_data)\n",
        "    print(\"User Preferences (Validated):\")\n",
        "    print(user_prefs.model_dump_json(indent=2))\n",
        "except ValidationError as e:\n",
        "    print(f\"Error validating user preferences: {e}\")\n",
        "    user_prefs = None\n",
        "\n",
        "# --- 2. Initial Itinerary Generation (CoT & Structured Output) ---\n",
        "# Reference: TravelItinerary Pydantic Model (defined in project_lib.py or stub above)\n",
        "\n",
        "# TODO: Craft the system prompt for initial itinerary generation.\n",
        "# This prompt must instruct the LLM to act as a detailed travel planner for AgentsVille.\n",
        "# It needs to consider all aspects of the `user_prefs`.\n",
        "# The output MUST be a JSON object that validates against the `TravelItinerary` Pydantic model.\n",
        "# Guide the LLM to create a coherent day-by-day plan, including activities,\n",
        "# a suggested packing list, an overall estimated budget, and relevant notes.\n",
        "# Remind it to ONLY output the JSON object.\n",
        "# Apply principles of Chain-of-Thought by asking for a comprehensive, well-reasoned plan\n",
        "# that covers all requirements.\n",
        "\n",
        "system_prompt_generate_itinerary = \"\"\"\n",
        "********** TODO: DEFINE YOUR SYSTEM PROMPT HERE **********\n",
        "Remember to specify the role, task, detailed output JSON structure (matching TravelItinerary),\n",
        "and instructions to consider all user preferences and output ONLY JSON.\n",
        "The JSON structure to follow is:\n",
        "{\n",
        "  \"trip_name\": \"string\", \"destination\": \"string\", \"duration_days\": \"integer\",\n",
        "  \"daily_plans\": [ { \"day_number\": \"integer\", \"theme\": \"string (optional)\",\n",
        "                   \"activities\": [ { \"time\": \"string\", \"description\": \"string\",\n",
        "                                     \"estimated_cost\": \"string (optional)\",\n",
        "                                     \"details\": \"string (optional)\" } ] } ],\n",
        "  \"suggested_packing_list\": [ { \"item\": \"string\", \"quantity\": \"integer (optional)\",\n",
        "                               \"notes\": \"string (optional)\" } ],\n",
        "  \"overall_estimated_budget\": \"string (optional)\",\n",
        "  \"notes\": \"string (optional)\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "user_prompt_itinerary_request = f\"\"\"\n",
        "Please generate a travel itinerary based on the following preferences:\n",
        "{user_prefs.model_dump_json(indent=2) if user_prefs else \"User preferences not available.\"}\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\\\nGenerating initial itinerary...\")\n",
        "initial_itinerary: Optional[TravelItinerary] = None\n",
        "raw_llm_itinerary_json_str = None\n",
        "\n",
        "if user_prefs:\n",
        "    messages_itinerary = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt_generate_itinerary},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_itinerary_request}\n",
        "    ]\n",
        "    # We expect a JSON object directly due to response_format\n",
        "    llm_output_for_itinerary = get_completion(messages_itinerary, response_format={\"type\": \"json_object\"})\n",
        "\n",
        "    if isinstance(llm_output_for_itinerary, str):\n",
        "        raw_llm_itinerary_json_str = llm_output_for_itinerary\n",
        "        try:\n",
        "            initial_itinerary_json = json.loads(raw_llm_itinerary_json_str)\n",
        "            initial_itinerary = TravelItinerary(**initial_itinerary_json)\n",
        "            print(\"\\\\nInitial Itinerary Generated and Validated Successfully!\")\n",
        "            display(Markdown(f\"### Trip Name: {initial_itinerary.trip_name}\"))\n",
        "            # print(initial_itinerary.model_dump_json(indent=2)) # For full details\n",
        "        except (ValidationError, json.JSONDecodeError) as e:\n",
        "            print(f\"\\\\nError processing itinerary JSON: {e}\")\n",
        "            print(f\"\\\\nLLM Response was:\\\\n{raw_llm_itinerary_json_str}\")\n",
        "    else:\n",
        "        print(\"\\\\nFailed to generate initial itinerary (unexpected response type or None).\")\n",
        "else:\n",
        "    print(\"User preferences not loaded, cannot generate itinerary.\")\n",
        "\n",
        "\n",
        "# --- 3. Tool-Using Agent for Enhancements (ReAct) ---\n",
        "# Now, create an AI agent that uses tools to answer follow-up questions or enhance the itinerary.\n",
        "\n",
        "print(\"\\\\nSchema for 'search_activities' tool (from available_tools):\")\n",
        "if \"search_activities\" in available_tools: # Check if stub or real lib loaded it\n",
        "    print(json.dumps(available_tools['search_activities']['parameters'], indent=2))\n",
        "\n",
        "# TODO: Craft the system prompt for the ReAct agent.\n",
        "# This is a complex prompt and a core part of the project.\n",
        "# Instructions for system_prompt_react_agent:\n",
        "# 1. Role: 'AI Travel Assistant for AgentsVille'.\n",
        "# 2. Context: It will have an existing itinerary (from user message) and its goal is to answer questions or enhance it using tools.\n",
        "# 3. THINK-ACT-OBSERVE Cycle:\n",
        "#    - THINK: Briefly outline its plan and reasoning for choosing an action/tool.\n",
        "#    - ACT:\n",
        "#        - If using tool(s), output *only* a valid JSON list of tool call objects: `[{\"name\": \"tool_name\", \"arguments\": {\"arg1\": \"value1\"}}]`\n",
        "#        - If providing a final answer, output `FINAL ANSWER:` followed by the text.\n",
        "# 4. Tool List: Provide the LLM with the list of available tools and their schemas (use `available_tools` to construct this part of the prompt).\n",
        "# 5. Examples: Provide clear examples of a THINK-ACT (tool call) sequence AND a THINK-FINAL ANSWER sequence.\n",
        "\n",
        "system_prompt_react_agent = f\\\"\\\"\\\"\n",
        "********** TODO: DEFINE YOUR REACT AGENT SYSTEM PROMPT HERE **********\n",
        "\n",
        "Remember to include:\n",
        "- The agent's role.\n",
        "- Instructions on the THINK-ACT-OBSERVE cycle.\n",
        "- The exact format for ACT tool calls (JSON list of LLMToolCall-like objects).\n",
        "- The exact format for FINAL ANSWER.\n",
        "- The full list of AVAILABLE TOOLS with their names, descriptions, and parameter schemas\n",
        "  (formatted from the `available_tools` dictionary).\n",
        "- At least one clear example of a tool-calling interaction (User -> AI THINK/ACT -> User OBSERVATION -> AI THINK/FINAL ANSWER).\n",
        "- At least one clear example of a direct final answer (User -> AI THINK/FINAL ANSWER).\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "# --- Simulate ReAct Agent Interaction ---\n",
        "react_messages: List[Dict[str, Any]] = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt_react_agent}\n",
        "]\n",
        "\n",
        "if initial_itinerary:\n",
        "    current_itinerary_str = initial_itinerary.model_dump_json(indent=2)\n",
        "    follow_up_request = \"Can you find a unique local craft workshop for the afternoon of Day 2? Also, what will the weather be like on Day 1 of my trip, assuming Day 1 is 2025-10-26?\"\n",
        "\n",
        "    user_message_content_for_react = f\\\"\\\"\\\"Here is the current travel itinerary:\n",
        "```json\n",
        "{current_itinerary_str}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Inb6pPstyg-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My follow-up request is: {follow_up_request}\n",
        "\\\"\\\"\\\"\n",
        "    react_messages.append({\"role\": \"user\", \"content\": user_message_content_for_react})\n",
        "else:\n",
        "    print(\"Initial itinerary not available. Skipping ReAct agent interaction for now.\")\n",
        "    # You could add a general user request here if you want the ReAct agent to build from scratch\n",
        "    # react_messages.append({\"role\": \"user\", \"content\": \"Help me plan a 3-day cultural trip to AgentsVille for a mid-range budget.\"})\n",
        "\n",
        "\n",
        "if initial_itinerary or not initial_itinerary: # Allow running even if initial itinerary failed, for general queries\n",
        "    MAX_TURNS = 7\n",
        "    final_answer_received = False\n",
        "\n",
        "    print(\"\\\\n--- Starting ReAct agent interaction ---\")\n",
        "    if len(react_messages) > 1: # if there's a user message\n",
        "        print_messages([react_messages[-1]])\n",
        "    else:\n",
        "        print(\"No initial user message for ReAct agent.\")\n",
        "\n",
        "\n",
        "    for turn in range(MAX_TURNS):\n",
        "        if len(react_messages) <= 1 and not initial_itinerary: # Safety break if no user input\n",
        "            print(\"Stopping ReAct loop: No user query to process.\")\n",
        "            break\n",
        "            \n",
        "        print(f\"\\\\n--- Agent Turn {turn + 1} ---\")\n",
        "        \n",
        "        llm_response_message_obj = get_completion(react_messages) # Returns message object or content string\n",
        "\n",
        "        if not llm_response_message_obj:\n",
        "            print(\"Agent did not provide a response. Ending interaction.\")\n",
        "            break\n",
        "        \n",
        "        current_ai_response_content = None\n",
        "        current_ai_tool_calls = None\n",
        "\n",
        "        if hasattr(llm_response_message_obj, 'tool_calls') and llm_response_message_obj.tool_calls:\n",
        "            current_ai_tool_calls = llm_response_message_obj.tool_calls\n",
        "            # For OpenAI v1.x, the content might be None when tool_calls are present\n",
        "            current_ai_response_content = llm_response_message_obj.content\n",
        "            \n",
        "            # Construct the message to append to history, including tool_calls\n",
        "            assistant_message_to_append = {\"role\": \"assistant\", \"content\": current_ai_response_content}\n",
        "            # The OpenAI library's message object for tool_calls is a list of ChatCompletionMessageToolCall objects.\n",
        "            # We need to convert it to the dict format expected by the API for subsequent calls.\n",
        "            assistant_message_to_append[\"tool_calls\"] = [\n",
        "                {\"id\": tc.id, \"type\": tc.type, \"function\": {\"name\": tc.function.name, \"arguments\": tc.function.arguments}}\n",
        "                for tc in current_ai_tool_calls\n",
        "            ]\n",
        "            react_messages.append(assistant_message_to_append)\n",
        "\n",
        "        elif isinstance(llm_response_message_obj, str):\n",
        "            current_ai_response_content = llm_response_message_obj\n",
        "            react_messages.append({\"role\": \"assistant\", \"content\": current_ai_response_content})\n",
        "        else:\n",
        "            print(\"Error: Unexpected response type from LLM that is not string or tool_call capable message object.\")\n",
        "            break # Exit loop on unexpected response type\n",
        "\n",
        "        print_messages([react_messages[-1]]) # Display AI's full response (THINK/ACT part)\n",
        "\n",
        "        # TODO: Implement the logic to handle the agent's response.\n",
        "        # This is the most complex part for you to build, applying what you learned about ReAct.\n",
        "        #\n",
        "        # 1. Check if `current_ai_response_content` (if it's a string) contains \"FINAL ANSWER:\".\n",
        "        #    If yes, set `final_answer_received = True` and `break` the loop.\n",
        "        #\n",
        "        # 2. If `current_ai_tool_calls` is present (meaning the LLM wants to use tools):\n",
        "        #    - Iterate through each `tool_call` in `current_ai_tool_calls`.\n",
        "        #    - Get `tool_name`, `tool_id`, and `tool_arguments_str` (which is a JSON string).\n",
        "        #    - Parse `tool_arguments_str` into a Python dictionary.\n",
        "        #    - Look up `tool_name` in your `available_tools` dictionary to get the actual Python function.\n",
        "        #    - Call the Python tool function with the parsed arguments: `tool_function(**parsed_arguments)`.\n",
        "        #    - Take the result from the Python tool function, convert it to a JSON string.\n",
        "        #    - Construct a 'tool' role message to append to `react_messages`:\n",
        "        #      `{\"role\": \"tool\", \"tool_call_id\": tool_id, \"name\": tool_name, \"content\": tool_result_json_string}`\n",
        "        #    - Print this tool message using `print_messages`.\n",
        "        #\n",
        "        # 3. If it's not a final answer and not a tool call (i.e., `current_ai_response_content` is text but no \"FINAL ANSWER:\"):\n",
        "        #    This might be the LLM asking a clarifying question or just thinking aloud without a proper ACT.\n",
        "        #    For this project, you can append a generic \"OBSERVATION: Please proceed by calling a tool or providing a FINAL ANSWER.\"\n",
        "        #    message from the 'user' role to `react_messages` to prompt the LLM again.\n",
        "        #    Or, if the content seems like a partial thought, you might just let the loop continue.\n",
        "\n",
        "        # --- START TODO: Implement ReAct Loop Logic (Parsing ACT, Calling Tools, Appending Observations) ---\n",
        "        \n",
        "        if current_ai_response_content and \"FINAL ANSWER:\" in current_ai_response_content:\n",
        "            pass # Replace with your logic\n",
        "        elif current_ai_tool_calls:\n",
        "            pass # Replace with your logic\n",
        "        else:\n",
        "            pass # Replace with your logic\n",
        "\n",
        "        # Example of how you might structure the tool call handling (you need to complete this):\n",
        "        # if current_ai_tool_calls:\n",
        "        #     for tool_call_obj in current_ai_tool_calls:\n",
        "        #         tool_name = tool_call_obj.function.name\n",
        "        #         tool_id = tool_call_obj.id\n",
        "        #         tool_args_str = tool_call_obj.function.arguments\n",
        "        #         \n",
        "        #         print(f\"  Attempting to call tool: {tool_name} with ID: {tool_id}\")\n",
        "        #         # ... (parse args_str, find function, call it, create tool message, append to react_messages) ...\n",
        "        #         # Remember to handle potential errors during parsing or tool execution.\n",
        "        \n",
        "        # --- END TODO: Implement ReAct Loop Logic ---\n",
        "\n",
        "    if not final_answer_received:\n",
        "        print(f\"\\\\nAgent did not provide a final answer after {MAX_TURNS} turns.\")\n",
        "\n",
        "\n",
        "# --- 4. Final Output and Reflection ---\n",
        "print(\"\\\\n--- Full ReAct Agent Conversation History (if run) ---\")\n",
        "if initial_itinerary or len(react_messages) > 1 : # only print if react loop was entered\n",
        "    print_messages(react_messages)\n",
        "\n",
        "# TODO: If the agent modified the itinerary or provided specific information in its FINAL ANSWER,\n",
        "# you might want to parse and display that here. For now, reviewing the printed conversation is key.\n",
        "\n",
        "# --- Reflection Questions: ---\n",
        "# (Keep the reflection questions as provided in the original starter)\n",
        "\n",
        "# --- Congratulations! ---\n",
        "# (Keep the congratulations message as provided)\n",
        "\n",
        "  ```"
      ],
      "metadata": {
        "id": "9vJX8hNdyg-P"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}